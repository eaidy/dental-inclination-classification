{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-05T01:18:52.639863Z",
     "start_time": "2024-02-05T01:18:52.636614Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "\"\"\"WILL BE ADDED TO A SEPARATE MODULE LATER\"\"\"\n",
    "\n",
    "def count_files(directory):\n",
    "    count = 0\n",
    "    # Iterate over all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Check if the path is a file (not a directory)\n",
    "        if os.path.isfile(os.path.join(directory, filename)):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def get_image_label(filename):\n",
    "    label = filename.split(\".\")[0].split(\"_\")[0]\n",
    "    return label\n",
    "\n",
    "def load_images_from_dataset(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        try:\n",
    "            # Attempt to read the image\n",
    "            image = cv2.imread(file_path)\n",
    "            # Check if the image is not None\n",
    "            if image is not None:\n",
    "                # Convert the image to RGB format\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                label = get_image_label(filename)\n",
    "                image_and_label = (image, label)\n",
    "                images.append(image_and_label)\n",
    "            else:\n",
    "                print(f\"Unable to read image file: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading image file {file_path}: {str(e)}\")\n",
    "    return images\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to read image file: /Users/eaidy/Repos/ML/inclination-classification/dataset/training/proclined/.DS_Store\n",
      "Unable to read image file: /Users/eaidy/Repos/ML/inclination-classification/dataset/training/retroclined/.DS_Store\n"
     ]
    }
   ],
   "source": [
    "\"\"\" LOAD IMAGES FROM DATASET\"\"\"\n",
    "current_dir = os.path.dirname(os.path.abspath(\"main.py\"))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "dataset_dir = os.path.join(parent_dir, \"dataset\")\n",
    "train_dir = os.path.join(dataset_dir, \"training\")\n",
    "test_dir = os.path.join(dataset_dir, \"test\")\n",
    "\n",
    "# Training Data Dirs\n",
    "proclined_training_dir = train_dir + \"/proclined\"\n",
    "retroclined_training_dir = train_dir + \"/retroclined\"\n",
    "\n",
    "proclined_training_images = load_images_from_dataset(proclined_training_dir)\n",
    "retroclined_training_images = load_images_from_dataset(retroclined_training_dir)\n",
    "\n",
    "merged_training_images = proclined_training_images + retroclined_training_images\n",
    "random.shuffle(merged_training_images)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T01:18:53.317025Z",
     "start_time": "2024-02-05T01:18:52.641549Z"
    }
   },
   "id": "338a85ec1d13ec56",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\" PRE-PROCESSING LAYER \"\"\"\n",
    "\n",
    "# RESIZE IMAGES TO A STANDARD DIMENSION and EXTRACT LABELS TO ANOTHER ARRAY\n",
    "\"\"\" When resizing, aspect ratio should be protected. Leaving it unconcerned now, will be handled later - ?\"\"\"\n",
    "resized_training_images = []\n",
    "labels = []\n",
    "for image, label in merged_training_images:\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    if label == \"proclined\":\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "    resized_training_images.append(image)\n",
    "\n",
    "# NUMPY ARRAY TRANSFORM\n",
    "merged_training_images = np.array(resized_training_images)\n",
    "\n",
    "# NORMALIZE IMAGES TO FLOATING POINT NUMBERS BETWEEN 0 and 1\n",
    "merged_training_images = merged_training_images / 255.0\n",
    "\n",
    "# DATA AUGMENTATION\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=60,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "final_training_data = datagen.flow(merged_training_images, labels, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T01:18:53.346476Z",
     "start_time": "2024-02-05T01:18:53.319055Z"
    }
   },
   "id": "f406a0f5471f1983",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\" CREATING THE MODEL AND TRAINING DATA \"\"\"\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')  # Change the output units based on your classification task\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(final_training_data, epochs=60, steps_per_epoch=len(merged_training_images) // 32)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5fc6d590f09ea97",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected value for `steps_per_epoch`. Received value is 0. Please check the docstring for `model.fit()` for supported values.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[62], line 20\u001B[0m\n\u001B[1;32m     10\u001B[0m test_data_generator \u001B[38;5;241m=\u001B[39m test_datagen\u001B[38;5;241m.\u001B[39mflow_from_directory(\n\u001B[1;32m     11\u001B[0m     test_dir,\n\u001B[1;32m     12\u001B[0m     target_size\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m224\u001B[39m, \u001B[38;5;241m224\u001B[39m),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     15\u001B[0m     shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m  \u001B[38;5;66;03m# No need to shuffle test data\u001B[39;00m\n\u001B[1;32m     16\u001B[0m )\n\u001B[1;32m     18\u001B[0m steps_per_epoch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(os\u001B[38;5;241m.\u001B[39mlistdir(test_dir)) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m---> 20\u001B[0m test_loss, test_acc \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_data_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTest accuracy:\u001B[39m\u001B[38;5;124m'\u001B[39m, test_acc)\n",
      "File \u001B[0;32m~/Repos/ML/inclination-classification/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/Repos/ML/inclination-classification/.venv/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1275\u001B[0m, in \u001B[0;36mDataHandler.__init__\u001B[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001B[0m\n\u001B[1;32m   1272\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model \u001B[38;5;241m=\u001B[39m model\n\u001B[1;32m   1274\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m steps_per_epoch \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 1275\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1276\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected value for `steps_per_epoch`. Received value is 0. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1277\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease check the docstring for `model.fit()` for supported \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1278\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalues.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1279\u001B[0m     )\n\u001B[1;32m   1281\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_epoch \u001B[38;5;241m=\u001B[39m steps_per_epoch\n\u001B[1;32m   1283\u001B[0m \u001B[38;5;66;03m# `steps_per_execution_value` is the cached initial value.\u001B[39;00m\n\u001B[1;32m   1284\u001B[0m \u001B[38;5;66;03m# `steps_per_execution` is mutable and may be changed by the DataAdapter\u001B[39;00m\n\u001B[1;32m   1285\u001B[0m \u001B[38;5;66;03m# to handle partial executions.\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: Unexpected value for `steps_per_epoch`. Received value is 0. Please check the docstring for `model.fit()` for supported values."
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rotation_range=60,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_data_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=4,\n",
    "    class_mode='binary',\n",
    "    shuffle=False  # No need to shuffle test data\n",
    ")\n",
    "\n",
    "steps_per_epoch = len(os.listdir(test_dir)) - 1\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_data_generator, steps=(steps_per_epoch) // 32)\n",
    "print('Test accuracy:', test_acc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T01:19:14.993419Z",
     "start_time": "2024-02-05T01:19:14.956848Z"
    }
   },
   "id": "c22a06d438d4f746",
   "execution_count": 62
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
